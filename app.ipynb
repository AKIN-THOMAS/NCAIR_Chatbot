{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.memory import MemoryViewMemory\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0301\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatWithNCAIR(question, history):\n",
    "    load_dotenv()\n",
    "\n",
    "    persist_directory = 'docs/chroma/'\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "    llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
    "\n",
    "    template = \"\"\"If the user says any greetings and says their name like \"hello I'm bishop\", \n",
    "        always reply by greeting the person and saying his name  \n",
    "        Use the following pieces of context to answer the question at the end. \n",
    "        If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "        Use as many sentences as needed to answer the question but Keep the answer as concise as possible. \n",
    "        Always be nice at the end of the answer.\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "    QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "    # Run chain\n",
    "    from langchain.chains import RetrievalQA\n",
    "    # question = \"Will interns go through the fabLab during the onboarding?\"\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "        retriever=vectordb.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": QA_CHAIN_PROMPT,\n",
    "            \"memory\": ConversationBufferMemory(\n",
    "                memory_key=\"history\",\n",
    "                input_key=\"question\"\n",
    "            )\n",
    "            })\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    "    )\n",
    "    retriever=vectordb.as_retriever()\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    "    )\n",
    "\n",
    "\n",
    "    result = qa({\"question\": question})\n",
    "    return result[\"answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_directory = 'docs/chroma/'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCAIR stands for the National Centre for Artificial Intelligence and Robotics. It is a research and development facility that is focused on emerging technologies, such as artificial intelligence, robotics, and the Internet of Things. NCAIR conducts research and development on emerging technologies. It also provides training and support for businesses and entrepreneurs who are interested in using these technologies. NCAIR is located in Abuja, Nigeria.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatWithNCAIR(\"What is NCAIR?\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.ChatInterface(fn=chatWithNCAIR,\n",
    "    chatbot=gr.Chatbot(height=300, min_width=40),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a question relating to NCAIR\"),\n",
    "    title=\"Chat with NCAIRðŸ’¬\",\n",
    "    description=\"Ask NCAIR any question\",\n",
    "    theme=\"soft\",\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",).queue()\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
