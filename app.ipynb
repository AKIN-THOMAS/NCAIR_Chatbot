{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.memory import MemoryViewMemory\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0301\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 results for vectordb\n",
      "input_variables=['chat_history', 'context', 'question'] output_parser=None partial_variables={} template='If the user says any greetings and says their name like \"hello I\\'m bishop\", \\n always reply by greeting the person and saying his name  \\n Use the following pieces of context to answer the question at the end. \\n If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer. \\n Use only 3 sentences but Keep the answer as concise as possible.\\n {context}\\n Previous conversation:\\n {chat_history}\\n New human question: {question}\\n Response:' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "# def chatWithNCAIR(question, history):\n",
    "load_dotenv()\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "template = \"\"\"If the user says any greetings and says their name like \"hello I'm bishop\", \n",
    " always reply by greeting the person and saying his name  \n",
    " Use the following pieces of context to answer the question at the end. \n",
    " If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    " Use only 3 sentences but Keep the answer as concise as possible.\n",
    " {context}\n",
    " Previous conversation:\n",
    " {chat_history}\n",
    " New human question: {question}\n",
    " Response:\"\"\"\n",
    "\n",
    "# QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\",\"chat_history\"], template=template)\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "print(f\"{vectordb._collection.count()} results for vectordb\")\n",
    "print(QA_CHAIN_PROMPT)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_CHAIN_PROMPT,\n",
    "        \"memory\": ConversationBufferMemory(\n",
    "            memory_key=\"history\",\n",
    "            input_key=\"question\"\n",
    "        )\n",
    "        })\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key='answer',\n",
    "    )\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(prompt, history):   \n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    get_chat_history=lambda h : h,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    "    )\n",
    "\n",
    "\n",
    "    result = qa({\"question\": prompt})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist_directory = 'docs/chroma/'\n",
    "# embedding = OpenAIEmbeddings()\n",
    "# vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "# vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The director of NCAIR is Mr Kashif Inuwa Abdullahi CCIE, as stated in the signed message by DG/CEO NITDA.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot(\"Who is the director of NCAIR?\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mallam Kashifu Inuwa Abdullahi CCIE is the Director General and Chief Executive Officer of the National Information Technology Development Agency (NITDA) and also the director of NCAIR. He is a thoroughbred IT professional with an impressive resume in public and private sector IT development, policy formulation, and IT governance. He holds various executive certificates from top-notch universities such as Harvard University, USA, University of Cambridge and Oxford University, UK. His strategic prowess is anchored in training from the world-renowned Massachusetts Institute of Technology (MIT).'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot(\"Tell about him?\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://24b9f554a270bb27e1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://24b9f554a270bb27e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-K0yZI60wc0q5sQ7XTUrjhAAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-K0yZI60wc0q5sQ7XTUrjhAAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-K0yZI60wc0q5sQ7XTUrjhAAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-K0yZI60wc0q5sQ7XTUrjhAAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-K0yZI60wc0q5sQ7XTUrjhAAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-K0yZI60wc0q5sQ7XTUrjhAAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "demo = gr.ChatInterface(fn=chatbot,\n",
    "    chatbot=gr.Chatbot(height=300, min_width=40),\n",
    "    # textbox=gr.Textbox(placeholder=\"Ask me a question relating to NCAIR\"),\n",
    "    title=\"Chat with NCAIR💬\",\n",
    "    description=\"Ask NCAIR any question\",\n",
    "    theme=\"soft\",\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
